\section{Datasets \& Methodology}\label{sec:methodology}

In this section we outline our measurement technique for establishing a breadth
based understanding of bidirectional censors on the internet. We cover the
details of the various probes that we send as well as the sources from which we
draw target addresses and domains that trigger censorship responses.

\FigProbeSend

\subsection{Selecting target domains}
\label{sec:methodology:domains}
Bidirectional censorship is triggered whenever a censor detects a domain present
in its block-list of domains to censor. The Citizen Lab \cite{TheCitiz6:online}
maintains a list of domains \cite{testlist} which are known to be present in the
block-lists of several censors. These lists contain country-specific domains
i.e\ domains that are tested specifically for each country with country specific
context (e.g\ local language) and global domains which contain content (e.g\
freedom of expression, gambling e.t.c.) commonly considered sensitive in
censoring countries. For this study, we used the global list to conduct our
measurements as we are concerned with measuring the prevalence of bidirectional
censorship globally i.e\ which countries deploy bidirectional censorship
strategies. The global list contains approximately 1400 domains.

We supplement this set with 10 control. These controls are not present
in any block-list, nor are they are sub-domains or substring matches of any
domain in a block-list that we are aware of. Three of these domains are
hosted in the US and provide valid A and AAAA records. This provides a baseline
against which we can determine whether or not responses are ``normal'' when
requests contain blocklisted domain names.

\subsection{Selecting IP Addresses}
\label{subsec:selecting-ips}

\FigAllocSize

Our goal in selecting target IP addresses for each experiment is to identify a
set of non-responsive hosts within IP address allocations that transit a link
monitored by a censor such that benign control probes receive a predictable
response or no response at all, but sensitive domains trigger characteristic
responses from the on path censor.

% In order to achieve a representative global view of bidirectional censorship
% we test as many countries and as many allocations in each country as possible.
We begin by collecting a list of all IP allocations announced by the 5 regional
registries \cite{herrbisc56:online} containing 155k IPv4 and
63k IPv6 allocations from a total of over 200 countries. We use
MaxMind \cite{IPGeoloc87:online} to assign the Autonomous System Numbers (ASNs)
and organization names to each of these allocations. We then filter out
organizations that do not have at least one IPv4 and one IPv6 allocation
resulting in 71k IPv4 and 20k IPv6 allocations.

It is uncommon that the entire IP allocation provided by RIRs is announced as
is, often being split and announced in several smaller allocations. Portions of
the allocated IP block sometimes remain unannounced by the organization.
Choosing IP addresses from the unannounced region of an IP block might reduce
the rate at which probes are truly routed into the country in question
potentially resulting in a false negative, under-representing the prevalence of
bidirectional censorship in a country. To increase the confidence that all
chosen IP addresses are routable and lower the chance of this type of false
negative result we chose IP addresses only from the announced prefixes of each
allocation. We used the \textit{University of Oregon Route Views Project}
\cite{RouteVie20:online} to get all the announced prefixes for each of the
allocated IP block. This resulted in a total of 313k IPv4 and 40k IPv6 prefixes.

For each announced prefix, we select a set of $N=10$ addresses at random. We
arrived at this number after a couple of considerations. First, scanning the
entirety of the addresses space for 1400 domains is infeasible for IPv4 and
impossible for IPv6. Second, our aim is to test for on path censorship on the
penultimate hop and not necessarily reach the end hosts themselves. This
technique allows us to test for bidirectional censorship while maintaining the
breadth of our measurements. Choosing 10 addresses from each of the announced
prefix in our allocation dataset results in over 3.5 million IP addresses.

\subsection{Identifying Bidirectional Censorship}
\label{sec:methodology:censorship}

We focus on identifying bidirectional censorship via injected responses to
ingress traffic. This allows us to send probes from external vantage points and
receive responses that we can classify as either expected or characteristic of
censorship. We do this for several different protocols that are known (or
suspected) to be censored. For each of the following probe types we first
conduct a measurement of control domains only to all target addresses. This is
followed by a complete measurement in which we send probes containing all
sensitive domains with control domains mixed in. For each experiment we stripe
IP by domain such that each domain is sent too all IPs before any individual IP
is given a second domain. This is done to prevent our scanner from overwhelming
any individual target address.

In between experiments we take several minutes to allow any potential residual
censorship to timeout before shuffling both addressed and domains and
initializing the scan for the next probe type.

\subsubsection{TCP}
While some firewall implementations explicitly look for singular TCP (TLS, HTTP,
or other) packets that violate their rules, others keep a modest amount of state
and require the TCP flow to be ``established'' before they will present
censorship behavior. However, because routing on the internet is not typically
symmetrical and response traffic often follows alternative routes, some high
performance firewall implementations will trigger censorship behavior with just
the unidirectional client-to-station flow of a TCP SYN packet, followed by an
ACK packet and a data packet with the PSH/ACK flags set. While this allows flows
that use heterogeneous routing to be included and censored, it also allows
falsified flows with non-existent endpoints to trigger a censorship response as
there is no validation that the TCP handshake successfully completed.

We take advantage of this by measuring censorship responses triggered by a
singular TCP PSH/ACK packet with data, as well as responses triggered by a
packet sequences of SYN -- ACK -- PSH/ACK with data.

Our \textbf{HTTP} probe data consists of a HTTP request crafted to trigger
censorship using blocklisted domains in the \texttt{HOST} header.
% Add/ Test Keyword based blocking?

Our \textbf{TLS} probe data consists of a TLS \texttt{ClientHello} crafted to
trigger censorship using blocklisted domains in the SNI extension.

\subsubsection{UDP}
To measure \textbf{DNS} we send one {\tt A} and one {\tt AAAA} query per domain
to each of our selected target addresses. This allows us to make a loose, but
direct comparison of censorship rates for IPv4 and IPv6 resource records.


Our \textbf{Quic} probe consists of a client initial frame that contains a
TLS1.3 {\tt ClientHello} with the domain in question in the SNI extension. In
following with the Quic specification the payload portion of the frame is
encrypted using an a key derived using an HKDF on our selected connection ID.
While on-path attackers can decrypt this initial packet and inspect the
plaintext TLS packet including SNI, they are forced to perform a relatively
costly HKDF in order to do so.

\subsubsection{Tagging}

Similar to the architecture of the zmap scanning tool, our probing architecture
uses many threads to craft and send packets and one independent thread to listen
and ingests responses. One consequence of this architecture is that we must
maintain a limited amount of state internally for each connection we create.
While injected responses to DNS probes may include the host name (in the
response Resource Record) other protocols are not guaranteed to do so. For
example, the TCP RST packets injected by the GFW in response to a TLS probe with
a censored SNI will not indicate what domain the original probe included.
Similar challenges exists for HTTP and Quic probes.

To solve this problem we employ a tagging system for outgoing packets such that
we can identify the details of the probe they correlate to and check the
validity of the response without tracking the full connection state from start
to finish.

We start by creating a 1-to-1 mapping from domain to a random number in the
range 1000-65535. We use this number as the source port for the outgoing packet
meaning that we can use the destination port of any response packet to lookup
the domain sent in the original probe. In order to ensure that response TCP
packets are associated with our measurement and not just sent randomly we set
the acknowledgement number of the outgoing probe to be the CRC32 of the source
port (from our domain mapping) and the target address. This allows our ingest
thread to quickly validate responses by checking:
\begin{gather*}
CRC32(PORT_{dst},ADDR_{src}) \stackrel{?}{=} SEQ - Len
\end{gather*}

For Quic responses that either return garbage or change the connection ID for
the server initial packet we need to have access to the 8 byte connection ID
sent in our probe. To make sure this is always available we set the source port
for the outgoing packets from our 1-to-1 domain map and then set the connection
ID to be the CRC64-ECMA of the source port and the target address for the
outgoing packet. That way response packets can statelessly derive the original
connection ID by computing the following for incoming packets.
\begin{gather*}
Conn\_ID = CRC64_{ECMA}(PORT_{dst},ADDR_{src})
\end{gather*}


\subsection{Ethics}\label{sec:methodology:ethics}

Our experimental design has incorporated ethical considerations into the
decision-making process at multiple stages. Censorship measurement has inherent
risks and trade-offs: better understanding of censorship can help support and
inform users, but specific measurements may carry risk to participants or
network users. Measurement of bidirectional censorship typically allows
researchers to limit the number of third parties implicated in experiments as
the censorship response can be triggered by either ingress or egress traffic
removing the need for cooperation by individual hosts or hosting services within
a censoring region. Vantage points are instead hosted in regions that do not
censor connections and allow for researchers to freely measure the internet.

The vantage that was used for data collection is connected to the internet with
a 1 Gbps interface that scanned using the default rates for our custom protocol
scanning tool (line rate). However, the structure of the scan was established
such that individual addresses and domains would be accessed in round robin
order --- \ie when sending probes every target address would receive a first
request before any target would receive the subsequent request.

We encourage readers to consult The Menlo Report~\cite{menlo}, its companion
guide~\cite{menlo-companion}, and the censorship specific ethical measurement
guidelines outlined by Jones \etal \cite{jones2015ethical} for further
discussion of ethical design for internet measurement.